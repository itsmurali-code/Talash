The information retrieval system for Wikipedia

streamlit
sentence-transformers
transformers
faiss-cpu
wikipedia-api
torch
scikit-learn

## ğŸ” LLM-Based Wikipedia QA System

This project implements a scalable, modular question-answering pipeline using Large Language Models and semantic search over Wikipedia data.

### âœ… Key Improvements

- **â±ï¸ 41% Faster**: Switched from PDF uploads to Wikipedia scraping; reduced average query latency from 5.8s â†’ 3.4s.
- **ğŸ¯ 31% More Accurate**: Replaced LLaMA3 with RoBERTa-base-SQuAD2 for extractive QA; boosted F1 score from 61.3% â†’ 80.5%.
- **âš™ï¸ 85% More Modular**: Rebuilt the architecture using LangChain modules for scraping, embedding, indexing, and QA.

### ğŸ”§ Tech Stack

`Python` Â· `LangChain` Â· `FAISS` Â· `sentence-transformers` Â· `HuggingFace` Â· `Streamlit`  
Models: `MiniLM-L6-v2`, `RoBERTa-base-SQuAD2`, `LLaMA3-8B-8192`

